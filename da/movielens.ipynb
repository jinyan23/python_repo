{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This notebook puts together data analytic concepts from the BCG RISE Business & Analytics Course (part-time) that I'm currently taking, and the MOOC Udemy Python for Data Science and Machine Learning Bootcamp course that I took for free, courtesy of NLB. The [MovieLens dataset](https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset) was covered in both courses and I will attempt to include a little more details than was covered in the courses. The dataset was downloaded from Kaggle, so it's a lot larger than the ones provided by the courses. The latest version of the dataset (up till 2019) can be obtained from [GroupLens](https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "#### Concepts\n",
    "1. Exploratory Data Analysis\n",
    "2. Data Visualization\n",
    "2. Linear Regression \n",
    "3. Keras Machine Learning \n",
    "\n",
    "#### Questions to Explore\n",
    "1. Which genres receive the highest ratings? How does this change over time, based on genres?\n",
    "2. Determine the temporal trends in the genres/tagging activity of the movies released.\n",
    "3. Do users biased towards a particular genre rate movies from other genres fairly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from datetime import datetime \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data & Exploratory Data Analysis\n",
    "This stands apart from the main data visualizations as exploratory data analysis (EDA) usually seeks to help the user better understand the data that is being dealt with. Quick and easy plots are usually used and certain functions such as `df.describe()` or `df.info()` shows the data types that we're dealing with. Data cleaning (extracting and removing year from movie titles) and formatting the data (e.g. `str` to `datetime`) are usually done alongside EDA, before the main data visualizations, feature engineering or data modelling are performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movie.csv\n",
    "file_path = \"../../dataset/movielens/\"\n",
    "\n",
    "movies = pd.read_csv(file_path + \"movie.csv\",\n",
    "                     sep=\",\",\n",
    "                     header=0,\n",
    "                     names=[\"movieid\", \"title\", \"genres\"])\n",
    "\n",
    "def extract_year(title):\n",
    "    \n",
    "    try:\n",
    "        year = int(title.rstrip()[-5:-1])       # something that can go wrong\n",
    "    except ValueError:\n",
    "        year = np.nan                           # run if error occurs\n",
    "    \n",
    "    return(year)\n",
    "\n",
    "movies[\"year\"] = movies[\"title\"].apply(extract_year)\n",
    "\n",
    "# remove the movies without year\n",
    "movies[movies[\"year\"].isna()].shape\n",
    "movies = movies[~movies[\"year\"].isna()]\n",
    "\n",
    "# extract just the movie title from the title column\n",
    "movies[\"title\"] = movies[\"title\"].apply(lambda movie: movie.rsplit(\" \", 1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple histogram\n",
    "ax = sns.histplot(x=\"year\", data=movies, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rating.csv\n",
    "\n",
    "# 20M rows, these codes will take some time\n",
    "ratings = pd.read_csv(file_path + \"rating.csv\",\n",
    "                      sep=\",\",\n",
    "                      header=0,\n",
    "                      names=[\"userid\", \"movieid\", \"rating\", \"timestamp\"])\n",
    "ratings[\"timestamp\"] = ratings[\"timestamp\"].apply(lambda t: datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\"))\n",
    "ratings[\"rating_year\"] = ratings[\"timestamp\"].apply(lambda t: t.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple countplot\n",
    "ax = sns.countplot(x=\"rating_year\", data=ratings, color=\"green\")\n",
    "ax_xticklabels = ax.get_xticklabels()\n",
    "ax.set_xticklabels(ax_xticklabels, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tag.csv\n",
    "tags = pd.read_csv(file_path + \"tag.csv\",\n",
    "                   sep=\",\",\n",
    "                   header=0,\n",
    "                   names=[\"userid\", \"movieid\", \"tag\", \"timestamp\"])\n",
    "tags = tags[~tags[\"tag\"].isna()]\n",
    "tags[\"timestamp\"] = tags[\"timestamp\"].apply(lambda t: datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the tags data, the presence of a tag by a user does not mean the user rated that movie. I assumed that one would rate a movie without leaving a tag, but that's not the case. We could figure out which users left a tag on a movie without rating them, but we're not going to do it here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the ratings of one particular movie with the tag \"killer fish\"\n",
    "fish_movieid = tags[tags[\"tag\"] == \"killer fish\"].iloc[0, 1]\n",
    "fish_movie = ratings[ratings[\"movieid\"] == fish_movieid]\n",
    "sns.countplot(x=\"rating\", data=fish_movie, color=\"blue\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more datafile listing the users' profiles that is not available on the Kaggle site. It might have been added by the BCG course for learning purposes. This datafile only contains a subset of the users from the `rating.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load users.dat\n",
    "users = pd.read_csv(file_path + \"users.dat\",\n",
    "                    encoding=\"ISO-8859-1\",\n",
    "                    engine=\"python\",\n",
    "                    sep=\"::\",\n",
    "                    names=[\"userid\", \"gender\", \"age\", \"occupation\", \"zipcode\"])\n",
    "\n",
    "# converting the feature age into age group\n",
    "users[\"age\"] = users[\"age\"].replace({1: \"Under 18\",\n",
    "                                     18: \"18-24\",\n",
    "                                     25: \"25-34\",\n",
    "                                     35: \"35-44\",\n",
    "                                     45: \"45-49\",\n",
    "                                     50: \"50-55\",\n",
    "                                     56: \"56+\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are other toy story spinoffs, we shall work with the main 3 animated films.\n",
    "toystory = movies[movies[\"title\"].isin([\"Toy Story\", \"Toy Story 2\", \"Toy Story 3\"])]\n",
    "toystory_ratings = ratings[ratings[\"movieid\"].isin(toystory[\"movieid\"])]\n",
    "toystory_ratings = toystory_ratings.merge(movies[[\"movieid\", \"title\"]], how=\"left\", on=\"movieid\")\n",
    "\n",
    "# Plotting a horizontal barplot, compressing the plot vertically\n",
    "sns.set_theme(style=\"white\", font=\"helvetica\", rc={\"figure.figsize\":(6,3)})\n",
    "\n",
    "# Plot barplot based on count of rating under each rating for Toy Story series\n",
    "ax = sns.countplot(toystory_ratings,\n",
    "                   y=\"rating\",\n",
    "                   hue=\"title\",\n",
    "                   #color=\"grey\",\n",
    "                   order=[5, 4, 3, 2, 1])\n",
    "\n",
    "# Adjust the aesthetics of the seaborn plot\n",
    "ax.set_title(\"Movie Ratings for Toy Story Series\")\n",
    "#ax.bar_label(ax.containers[0], padding=3, size=\"small\")\n",
    "#ax.bar_label(ax.containers[1], padding=3, size=\"small\")\n",
    "#ax.bar_label(ax.containers[2], padding=3, size=\"small\")\n",
    "ax.set_xlabel(\"Count\", labelpad=10)\n",
    "ax.set_xticks([0, 5000, 10000, 15000, 20000])\n",
    "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), \",\")))\n",
    "ax.set_ylabel(\"Rating\", labelpad=10)\n",
    "sns.move_legend(ax, \"lower right\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[:], labels=labels[:], frameon=False)\n",
    "\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Questions\n",
    "#### Question 1: Which genres receive the highest ratings? How does this change over time, based on genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the genres into long form\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(lambda g: g.split(\"|\"))\n",
    "\n",
    "genres_wide = movies[\"genres\"].apply(lambda x: pd.Series(1, x))\n",
    "genres = list(genres_wide.columns)\n",
    "genres_wide = pd.concat([movies.drop(\"genres\", axis=1), genres_wide], axis=1)\n",
    "\n",
    "movies = pd.melt(genres_wide, id_vars=[\"movieid\", \"title\", \"year\"], value_vars=genres)\n",
    "movies = movies[~movies[\"value\"].isna()]\n",
    "movies = movies.drop(\"value\", axis=1)\n",
    "movies.rename({\"variable\":\"genre\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check if the data frame is reshaped correctly\n",
    "movies.query(\"title == 'Toy Story'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging ratings (with movie ratings and rating_years) and movies (with movie titles and genres)\n",
    "# It turns from a 20M rows df to a 53M rows df\n",
    "master = ratings.merge(movies, on=\"movieid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = master.groupby([\"genre\"], as_index=False)\n",
    "genre_rating = (grouped[\"rating\"].aggregate([np.mean, np.count_nonzero])\n",
    "                                 .rename(columns={\"mean\": \"rating_mean\",\n",
    "                                                  \"count_nonzero\": \"rating_count\"})\n",
    "                                 .reset_index())                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=genre_rating.sort_values(by=\"rating_mean\", ascending=False),\n",
    "                 x=\"rating_mean\",\n",
    "                 y=\"genre\",\n",
    "                 color=\"green\");\n",
    "ax.bar_label(ax.containers[0], padding=3, size=\"small\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the years in question. Will skip year 1995 since there are only 10 ratings.\n",
    "# master[\"rating_year\"].value_counts().sort_index()\n",
    "\n",
    "# We shall just choose the top 5 genres in 1996 and 2015 and see how they fare over the years with a lineplot\n",
    "year_1996 = master[master[\"rating_year\"] == 1996]\n",
    "year_2015 = master[master[\"rating_year\"] == 2015]\n",
    "\n",
    "rating_1996 = (year_1996.groupby(\"genre\", as_index=False)[\"rating\"]\n",
    "                        .aggregate([np.mean, np.count_nonzero])\n",
    "                        .rename(columns={\"mean\": \"rating_mean\",\n",
    "                                         \"count_nonzero\": \"rating_count\"})\n",
    "                        .reset_index()\n",
    "                        .sort_values(by=\"rating_mean\", ascending=False))\n",
    "\n",
    "rating_2015 = (year_2015.groupby(\"genre\", as_index=False)[\"rating\"]\n",
    "                        .aggregate([np.mean, np.count_nonzero])\n",
    "                        .rename(columns={\"mean\": \"rating_mean\",\n",
    "                                         \"count_nonzero\": \"rating_count\"})\n",
    "                        .reset_index()\n",
    "                        .sort_values(by=\"rating_mean\", ascending=False))\n",
    "\n",
    "top_1996 = list(rating_1996.head(n=5)[\"genre\"])\n",
    "top_2015 = list(rating_2015.head(n=5)[\"genre\"])\n",
    "\n",
    "req_genres = set(top_1996+top_2015)\n",
    "\n",
    "req_ratings = master[master[\"genre\"].isin(req_genres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = req_ratings.groupby([\"genre\", \"rating_year\"], as_index=False)\n",
    "genre_rating = (grouped[\"rating\"].aggregate([np.mean, np.count_nonzero])\n",
    "                                 .reset_index()\n",
    "                                 .rename(columns={\"mean\": \"rating_mean\",\n",
    "                                                  \"count_nonzero\": \"rating_count\"}))\n",
    "genre_rating = genre_rating[genre_rating[\"rating_year\"] != 1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", font=\"helvetica\", rc={\"figure.figsize\":(9,3), \"figure.dpi\":300})\n",
    "ax = sns.lineplot(data=genre_rating,\n",
    "                  x=\"rating_year\",\n",
    "                  y=\"rating_mean\",\n",
    "                  hue=\"genre\")\n",
    "\n",
    "ax.set_xticks([1995, 2000, 2005, 2010, 2015])\n",
    "ax.set_yticks([3, 4, 5])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[:], labels=labels[:], frameon=False, ncol=4);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Determine the temporal trends in the genres/tagging activity of the movies released.\n",
    "* Determine most-seen tags for each genre and each tag year\n",
    "* The genre and tag year can be user-input with `input()` function. Then pass that input value into the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tags and movies dataframe to get the tags and genres into one dataframe\n",
    "tags[\"tag_year\"] = tags[\"timestamp\"].apply(lambda t: t.year)\n",
    "tag_movies = tags.merge(movies, on=\"movieid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word cloud of tags for the genre\n",
    "animation_df_2006 = tag_movies.query(\"genre == 'Animation' and tag_year == 2006\")\n",
    "animation_df_2015 = tag_movies.query(\"genre == 'Animation' and tag_year == 2015\")\n",
    "\n",
    "# wordcloud requires a text input instead of a list input\n",
    "animation_tags_2006 = \" \".join(list(animation_df_2006[\"tag\"]))\n",
    "cloud_2006 = WordCloud().generate(animation_tags_2006)\n",
    "animation_tags_2015 = \" \".join(list(animation_df_2015[\"tag\"]))\n",
    "cloud_2015 = WordCloud().generate(animation_tags_2015)\n",
    "\n",
    "# wordcloud drawing\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(cloud_2006, interpolation=\"bilinear\")\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title(\"2006\")\n",
    "ax2.imshow(cloud_2015, interpolation=\"bilinear\")\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title(\"2015\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top fives tags for the different genres (using Comedy here as an example)\n",
    "comedy_df = tag_movies[tag_movies[\"genre\"] == \"Comedy\"]\n",
    "comedy_df_count = comedy_df.groupby([\"tag\", \"tag_year\"], as_index=False).aggregate(ncount = (\"tag\", np.count_nonzero))\n",
    "comedy_df_count = comedy_df_count.sort_values(by=[\"tag_year\", \"ncount\"], ascending=[True, False])\n",
    "\n",
    "comedy_head_count = comedy_df_count.groupby(\"tag_year\", as_index=False).head(5)\n",
    "comedy_head_count = comedy_head_count[comedy_head_count[\"tag_year\"] != 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for top five tags for comedy genre in a particular year\n",
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "req_year = 2008\n",
    "ax = sns.barplot(data=comedy_head_count.query(\"tag_year == {}\".format(req_year)),\n",
    "                 y=\"tag\",\n",
    "                 x=\"ncount\")\n",
    "ax.set_title(\"{}\".format(req_year));\n",
    "ax.bar_label(ax.containers[0], padding=3, size=\"small\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do users biased towards a particular genre rate movies from other genres fairly?\n",
    "Basically for example, do users who favor Action movies (rate high on action movies) rate movies from other genres such as Musical or Drama as well as users who don't rate high on Action movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the master dataframe from question 1\n",
    "\n",
    "# Narrowing the samples to work on.\n",
    "# Selecting ratings from just year 2006-2015\n",
    "master_req = master.query(\"2006 < rating_year < 2015\")\n",
    "\n",
    "# Selecting users who have rated > 100 action films\n",
    "# Average rating for action films >= 4.0 = high_action_users\n",
    "# Average rating for action films < 3.5 = low_action_users\n",
    "user_count = (master_req.groupby([\"userid\", \"genre\"], as_index=False)\n",
    "                        .aggregate(rating_mean = (\"rating\", np.mean), count = (\"rating\", np.count_nonzero)))\n",
    "\n",
    "high_action_users = list(user_count.query(\"count > 100 and  genre == 'Action' and rating_mean >= 4.0\")[\"userid\"])\n",
    "low_action_users = list(user_count.query(\"count > 100 and  genre == 'Action' and rating_mean < 3.5\")[\"userid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting only required users with high action and low action ratings.\n",
    "action_df = master_req[master_req[\"userid\"].isin(high_action_users + low_action_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the high action and low action into two categorical groups.\n",
    "def assign_group(df):\n",
    "    \n",
    "    if df[\"userid\"] in high_action_users:\n",
    "        return(\"high_action\")\n",
    "    elif df[\"userid\"] in low_action_users:\n",
    "        return(\"low_action\")\n",
    "\n",
    "# Not efficient to df.apply(function) across 5.8M rows.\n",
    "action_df[\"action_group\"] = action_df.apply(assign_group, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas vectorization is much faster.\n",
    "mask = action_df[\"userid\"].isin(high_action_users)\n",
    "action_df.loc[mask, \"action_group\"] = \"high_action\"\n",
    "mask2 = action_df[\"userid\"].isin(low_action_users)\n",
    "action_df.loc[mask2, \"action_group\"] = \"low_action\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As one movie is tagged to multiple genres, to avoid correlation and misinterpretation,\n",
    "# Next is to remove movies with the action genre tagged to it.\n",
    "action_movies = action_df[action_df[\"genre\"] == \"Action\"][\"movieid\"].unique()\n",
    "\n",
    "non_action_subset = action_df[~action_df[\"movieid\"].isin(action_movies)]\n",
    "non_action_subset = non_action_subset[non_action_subset[\"genre\"] != \"(no genres listed)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot barplots of rating differences in genres between the two groups\n",
    "sns.barplot(data=non_action_subset,\n",
    "            x=\"rating\",\n",
    "            y=\"genre\",\n",
    "            hue=\"action_group\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barplot shows the average ratings of movies of different genres across the two groups (high action & low action). Movies with \"Action\" tagged onto them were already removed from the plot. So it seems that users who tend to rate high on action movies, generally give movies high ratings across the different genres (with Film-Noir as the only exception), which is a rather odd conclusion. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "We're going to perform a inner merge of the three datasets: `movies`, `ratings` and `users`. This will result in a truncated dataset with much lesser rating entries as compared to the ones used above. \n",
    "\n",
    "Then we'll perform a one-hot encoding to convert all categorical data into `0` and `1` to be fitted into the linear model, and also the keras model later on. \n",
    "\n",
    "Then we need to check for the assumptions if the data can be fitted into the linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding of movie genres with MultiLabelBinarizer()\n",
    "movies_two = movies[movies[\"genres\"] != \"(no genres listed)\"]\n",
    "genres_list = movies_two[\"genres\"].apply(lambda g: g.split(\"|\"))\n",
    "\n",
    "mlb = MultiLabelBinarizer()         \n",
    "coded_df = pd.DataFrame(mlb.fit_transform(genres_list),\n",
    "                        columns=mlb.classes_)\n",
    "\n",
    "movies_three = pd.concat([movies_two.drop(\"genres\", axis=1), coded_df], axis=1)\n",
    "\n",
    "# Dataset merging\n",
    "master = pd.merge(users, ratings, how=\"inner\", on=\"userid\")\n",
    "master = pd.merge(master, movies_three, how=\"inner\", on=\"movieid\")\n",
    "\n",
    "# Perform one-hot encoding of gender and age group\n",
    "gender_dummy = pd.get_dummies(master[\"gender\"], drop_first=True)\n",
    "age_dummy = pd.get_dummies(master[\"age\"], drop_first=True)\n",
    "new_master = pd.concat([master, gender_dummy, age_dummy], axis=1).drop([\"gender\", \"age\"], axis=1)\n",
    "\n",
    "# Drop another two columns: zipcode and movie title as they probably do not affect movie ratings\n",
    "new_master = (new_master.drop([\"zipcode\", \"title\", \"timestamp\", \"movieid\"], axis=1)\n",
    "                        .dropna(axis=0, how='any'))\n",
    "\n",
    "# All features should be numerical now\n",
    "new_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Assumptions (to-do)\n",
    "\n",
    "# Multicolinearity\n",
    "corrmat = new_master.corr(numeric_only=True)\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, cmap = 'viridis');\n",
    "\n",
    "# Remove correlated features\n",
    "# Also possible to use VIF Factor\n",
    "corr_cols = [\"Action\",      # Adventure\n",
    "             \"Children\",    # Animation\n",
    "             \"Comedy\",      # Thriller\n",
    "             \"25-34\"]       # 35-44\n",
    "\n",
    "new_master = new_master.drop(corr_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting to train/test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_master.drop(\"rating\", axis=1), \n",
    "                                                    new_master[\"rating\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=2023)\n",
    "# Linear Regression model\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train);\n",
    "\n",
    "# Rating prediction with linear regression model\n",
    "y_train_pred = lm.predict(x_train)\n",
    "y_test_pred = lm.predict(x_test)\n",
    "\n",
    "# Plot actual against fitted ratings\n",
    "plt.scatter(y_train, y_train_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of all the features.\n",
    "cdf = pd.DataFrame(lm.coef_, x_train.columns, columns=[\"coef\"])\n",
    "\n",
    "# Comparing RMSE of train  and test predictions\n",
    "print(\"Train MAE:\", metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Test MAE:\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"\")\n",
    "print(\"Train MSE:\", metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(\"\")\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 20:27:05.858178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow - Keras\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Google Developer ML Course Colab\n",
    "def build_model(my_learning_rate):\n",
    "    \n",
    "    # Build a sequential model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Add one linear layer to the model to yield a simple linear regressor\n",
    "    model.add(tf.keras.layers.Dense(units=1, input_shape=(8,)))\n",
    "    \n",
    "    # Compile the model topography into code that TensorFlow can efficiently execute.\n",
    "    # Configure training to minimize the model's mean squared error.\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=my_learning_rate),\n",
    "                  loss=\"mean_squared_error\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "def train_model(model, feature, label, my_epochs, my_batch_size=None):\n",
    "    # Feed a dataset into the model to train it.\n",
    "    \n",
    "    history = model.fit(x=feature,\n",
    "                        y=label,\n",
    "                        batch_size=my_batch_size,\n",
    "                        epochs=my_epochs)\n",
    "    \n",
    "    # Gather the model's trained weight and bias.\n",
    "    trained_weight = model.get_weights()[0]\n",
    "    trained_bias = model.get_weights()[1]\n",
    "    \n",
    "    # The list of epochs is stored separately from the rest of the history\n",
    "    epochs = history.epoch\n",
    "    \n",
    "    # Isolate the root mean squared error for each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    rmse = hist[\"root_mean_squared_error\"]\n",
    "    \n",
    "    return(trained_weight, trained_bias, epochs, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "    \n",
    "    plt.xlabel(\"feature\")\n",
    "    plt.ylabel(\"label\")\n",
    "    plt.scatter(feature, label)\n",
    "    \n",
    "    x0 = 0\n",
    "    y0 = trained_bias\n",
    "    x1 = feature[-1]\n",
    "    y1 = trained_bias + (trained_weight * x1)\n",
    "    plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, rmse, label=\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting hyperparamters\n",
    "learning_rate = 100\n",
    "epochs = 450\n",
    "batch_size = 10000\n",
    "\n",
    "keras_col = [\"Documentary\", \"Drama\", \"War\", \"Animation\", \"Crime\", \"Film-Noir\", \"Horror\", \"Mystery\"]\n",
    "my_features = x_train[keras_col]\n",
    "my_label = y_train\n",
    "\n",
    "\n",
    "my_model = build_model(learning_rate)\n",
    "trained_weight, trained_bias, epochs, rmse = train_model(model=my_model, \n",
    "                                                         feature=my_features, \n",
    "                                                         label=my_label,\n",
    "                                                         my_epochs=epochs,\n",
    "                                                         my_batch_size=batch_size)\n",
    "plot_the_model(trained_weight, trained_bias, my_features, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_model(trained_weight, trained_bias, my_features, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015). DOI=http://dx.doi.org/10.1145/2827872\n",
    "\n",
    "Jesse Vig, Shilad Sen, and John Riedl. 2012. The Tag Genome: Encoding Community Knowledge to Support Novel Interaction. ACM Trans. Interact. Intell. Syst. 2, 3: 13:1â€“13:44. DOI=https://doi.org/10.1145/2362394.2362395"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5892030bfe97ad8f51fa969f617daa0837a0582626086e3c317af7b5723fcca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
